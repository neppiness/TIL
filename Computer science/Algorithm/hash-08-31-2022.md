[TIL on August 31st, 2022](../../TIL/2022/08/08-31-2022.md)
# **Hash**

### Data structure, hash
- Time complexity of O(1) for insert, erase, find and update

#### Time complexity of an array
- O(1): to find a certain element
- O(N): to delete or to insert an element in middle of an array

#### Linked list
- O(1): to delete or to insert an element in middle of an array
- O(N): to find a certain element

### Hash function (from wikipedia)
- A hash function is any function that can be used to map data of arbitrary size to fixed-size values
- The values returned by a hash function are called hash values, hash codes, digests, or simply hashes
- The values are usually used to index a fixed-size table called a hash table
- Use of a hash function to index a hash table is called hashing or scatter storage addressing

### Collision
- If we use the last four numbers of a card
  * 0000 0000 0000 5135 / 9999 9999 9999 5135
  * It could not be distinguished by hash value: it is called as collision
- To resolve a collision, two major methods are developed: Chaining and Open addressing

### Collision resolution
#### Chaining
- Chaining gives an linked list to an index (also C++ vector could work)
- Insertion added a value to an linked list
- Erase, find, and update could be done as insertion

- Ideally, inserting, erasing, finding, and updating of hash could be done in O(1)
- Collision decreases a performance of hash and it's not only for Chaining but Open Addressing

#### Open Addressing
- Like an array, some data with same indices is saved in the following addresses
- ex) Four elements with same 3333 index are placed at 3333 to 3336 in sequence

### Probing
#### Linear probing
- To linearly search a data: cache hit rate is higher
- Clustering decreases a performance of Linear probing
  * As data cluster increases the number of data to check

#### Quadratic probing
- Search a data with jump to 1, 4, 9, ..., and n^2th indices from the initial index
- Cache hit rate is not bad
- Clustering occurs less than linear probing but it has a limitation

### Double hashing
- Use one more hash function to find next position
- Cache hit rate drastically decreases

### STL
#### unordered_set
```cpp
void unordered_set_example(){
  unordered_set<int> s;
  s.insert(-10); s.insert(100); s.insert(15); // {-10, 100, 15}
  s.insert(-10); // {-10, 100, 15}
  cout << s.erase(100) << '\n'; // {-10, 15}, 1
  cout << s.erase(20) << '\n'; // {-10, 15}, 0
  if(s.find(15) != s.end()) cout << "15 in s\n";
  else cout << "15 not in s\n";
  cout << s.size() << '\n'; // 2
  cout << s.count(50) << '\n'; // 0
  for(auto e : s) cout << e << ' ';
  cout << '\n';
}
```
- `unordered_set` is based on set, so duplicated elements are not listed on it

#### unordered_multiset
- `unordered_multiset` allows duplicates: you can insert the same element that is already in a set
- `erase` function erases not only a given argument but all the elements that have the same value
- If the number of finding element is x, the time complexity of `count` function is O(x)
```cpp
void undordered_multiset_example(){
  unordered_multiset<int> ms;
  ms.insert(-10); ms.insert(100); ms.insert(15); // {-10, 100, 15};
  ms.insert(-10); // {-10, -10, 100, 15}
  cout << ms.size() << '\n'; // 5
  cout << ms.erase(15) << '\n'; // {-10, -10, 100}, 2
  ms.erase(ms.find(-10)); // {-10, 100}
  ms.insert(100); // {-10, 100, 100}
  ms.erase(100); // {-10}
  cout << ms.count(100); // 1
}
```

#### unordered_map
- The function `unordered_map` is in the header `unordered_map`
```cpp
void unordered_map_example(){
  unordered_map<string, int> m;
  m["hi"] = 123;
  m["bkd"] = 1000;
  m["gogo"] = 165; // ("hi", 123), ("bkd", 1000), ("gogo", 165)

  cout << m.size() << '\n'; // 3

  m["hi"] = -7; // ("hi", -7), ("bkd", 1000), ("gogo", 165)

  if(m.find("hi") != m.end())cout << "hi in m\n";
  else cout << "hi not in m\n";
  
  m.erase("bkd"); // ("hi", -7), ("gogo", 165)
  
  for(auto e : m)
    cout << e.first << ' ' << e.second << '\n';
}
```
- unordered_map doesn't allow duplicated elements
  * unordered_multimap does, but it is not useful

### Load factor
- Chaining and open addressing need to define a size of a hash table
- A factor that the number of elements divided by a size of a hash table is called as a load factor:
  * As load factor increases:
    - Collisions occur more frequently
    - Less amount of memory is required
    - Higher cache hit rate 
  * Otherwise, as load factor decreases:
    - Collisions occur less frequently
    - More memory is needed
    - Lower cahce hit rate
- For chaining, the load factor should not be greater than 1
- Otherwise, for open addressing, the load factor should not be greater than 0.75
- For PS purpose, we could use a load factor of 0.5
- Use a prime number as a hash table size (such as 1000003)

### Implementation
- [Chaining](./hash-imp1-09-01-2022.cpp): now implementing

___

### References
1. [[실전 알고리즘] 0x15강 - 해시](https://blog.encrypted.gg/1009)
2. [Hash function from wikipedia](https://en.wikipedia.org/wiki/Hash_function)
3. [Double hashing from wikipedia](https://en.wikipedia.org/wiki/Double_hashing)
4. [unordered_map](https://cplusplus.com/reference/unordered_map/unordered_map/)